{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec682c9e-67c0-456e-843f-3ac4044f44c0",
   "metadata": {},
   "source": [
    "# Testing Revolve checkpointing: Burger's equation\n",
    "\n",
    "This notebook aims to execute tests to verify the pyadjoint with checkpointing implementation.\n",
    "\n",
    "In the current case, we consider Burger's equation, which is a non-linear equation for the advection and\n",
    "diffusion of momentum. Here we choose to write the Burgers equation in\n",
    "one dimension:\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} - \\nu \\frac{\\partial^2 u}{\\partial x^2} = 0.\n",
    "$$\n",
    "\n",
    "Additional information about time and spatial discretisation is available in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e70de-b653-4d92-9284-7dea77cb3b72",
   "metadata": {},
   "source": [
    "As usual, we begin by importing Firedrake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d3dc1a-fc07-4dc0-9e65-239b084e4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "firedrake:WARNING OMP_NUM_THREADS is not set or is set to a value greater than 1, we suggest setting OMP_NUM_THREADS=1 to improve performance\n"
     ]
    }
   ],
   "source": [
    "from firedrake import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2318a-cce8-4af5-b337-599f9e7557fd",
   "metadata": {},
   "source": [
    "We now import the `firedrake.adjoint` package, which computes adjoint-based gradient automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f44e9f5-1c1e-4d86-a63b-dd673b181c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from firedrake.adjoint import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a7579-2b1b-4b4a-8aef-f39f4c5822a6",
   "metadata": {},
   "source": [
    "The use of adjoint calculations to compute the gradient of a quantity of interest resulting from the solution of a system of partial differential equations (PDEs) is widespread and well-established. The resulting gradient may be employed for many purposes, eg, for inverse problems.\n",
    "\n",
    "Solving the adjoint to a non-linear time-dependent PDE requires the forward PDE to be solved first. The adjoint PDE is then solved in a reverse time order, but depends on the forward state. Storing the entire forward state in preparation for the adjoint calculation has a memory footprint linear in the number of time steps. In contrast, checkpointing approaches store only the state required to restart the forward calculation from a limited set of steps. As the adjoint calculation progresses, the forward computation is progressively rerun from the latest available stored state up to the current adjoint step. This enables less forward state to be stored, at the expense of a higher computational cost as forward steps are run more than once. \n",
    "\n",
    "[Griewank and Walther (2000)](https://dl.acm.org/doi/pdf/10.1145/347837.347846) proposed a checkpointing algorithm referred to as Revolve that is available in the Python package [checkpoint_schedules](https://www.firedrakeproject.org/checkpoint_schedules/). \n",
    "\n",
    "[checkpoint_schedules](https://www.firedrakeproject.org/checkpoint_schedules/) provides schedules for step-based incremental checkpointing of the adjoints to computer models. The schedules contain instructions indicating the sequence of forward and adjoint steps to be executed and the data storage and retrieval to be performed. checkpoint_schedules can be installed using `pip`: \n",
    "\n",
    "`pip install checkpoint-schedules`\n",
    "\n",
    "To employ Revolve checkpointing in your adjoint-based gradient, you would install checkpoint_schedules and import the Revolve algorithms as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d1da3b-8bde-414c-9cb5-e7f0f42c09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkpoint_schedules import Revolve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf033f2-8b56-46f8-9bb4-a4d94e459e83",
   "metadata": {},
   "source": [
    "On employing `firedrake.adjoint`, we need to start taping (annotating) the Firedrake operations we run in order to be able to execute the adjoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d343b59-db87-4eb0-a6e4-71c1cb229b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continue_annotation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569120bf-2ace-4d1b-9963-0cfbd8797f71",
   "metadata": {},
   "source": [
    "We can now proceed to set up the problem. We choose a resolution and set up a unit interval mesh and degree 2 continuous Lagrange polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edbbc219-788a-4d68-8e21-e320e87d85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "mesh = UnitIntervalMesh(n)\n",
    "V = FunctionSpace(mesh, \"CG\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb429a-713c-43fb-a2e1-6b63b0fa266c",
   "metadata": {},
   "source": [
    "Next, we choose the end step and the time-step adopted in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ec6208-95cb-4387-a0b4-1dec9b7df039",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 0.05\n",
    "timestep = 1.0/n\n",
    "steps = int(end/float(timestep)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca09e3ff-2368-4a05-aaee-c298e3b9f1c4",
   "metadata": {},
   "source": [
    "We are employing backward Euler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db670e7a-346a-48f6-beaa-371afd5f8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dt(u, u_, timestep):\n",
    "    return (u - u_)/timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d21d6-782a-4ab9-9537-ab76e19c0c95",
   "metadata": {},
   "source": [
    "We then write a function to compute the cost functional which is given by the expression:\n",
    "$$\n",
    "\\min_{J, u, u_0} \\ \\int_{\\Omega} u \\cdot \\nabla u\\ + u_0 \\cdot \\nabla u_0\\,\\text{d}x \n",
    "$$\n",
    "where $u_0$ is the initial condition $u_0 = u(x, 0) = sin (2\\pi x)$. The objective is minimising the cost function subject to the burger's equation and Dirichlet conditions $u(0, t) = u(1, t) = 0.0$.\n",
    "\n",
    "Below, the function `J` computes the forward solver, i.e., Burger's equation and the cost function. The arguments of `J` are the initial condition `ic`, the solver type `solve_type` and the checkpointing that is a `bool` type. \n",
    "\n",
    "Within `J`, we set the `u_` and `u` (lines 2 and 3) which are the solution functions for the current and the next timestep. The cost function is computed at the line 30. \n",
    "\n",
    "The time advancing is executed with a `for` loop. If `checkpointing=True`, we run the  `tape.timestepper` iterator that advances the tape timestep. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a45b5d6-3d1a-4e7b-9711-54467df8dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(ic, checkpointing):\n",
    "    u_ = Function(V)\n",
    "    u = Function(V)\n",
    "    v = TestFunction(V)\n",
    "    u_.assign(ic)\n",
    "    nu = 0.0001\n",
    "    F = (Dt(u, u_, timestep)*v\n",
    "         + u*u.dx(0)*v + nu*u.dx(0)*v.dx(0))*dx\n",
    "    bc = DirichletBC(V, 0.0, \"on_boundary\")\n",
    "\n",
    "    problem = NonlinearVariationalProblem(F, u, bcs=bc)\n",
    "    solver = NonlinearVariationalSolver(problem)\n",
    "\n",
    "    def time_advance():\n",
    "        solver.solve()\n",
    "        u_.assign(u)\n",
    "    tape = get_working_tape()\n",
    "    t = 0\n",
    "    if checkpointing:\n",
    "        for _ in tape.timestepper(np.arange(t, end + float(timestep), float(timestep))):\n",
    "            time_advance()\n",
    "    else:\n",
    "        for _ in np.arange(t, end + float(timestep), float(timestep)):\n",
    "            time_advance()\n",
    "\n",
    "    return assemble(u_*u_*dx + ic*ic*dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a735cca-4682-4de1-8781-2ff6183f37e9",
   "metadata": {},
   "source": [
    "We write a function to execute tests with the burger's equation when computing the automated gradient with the checkpointing algorithms. We need to inform the adjoint solver to employ the checkpointing algorithm in the gradient computations. That is achieved with code line 7, i.e., with the code `tape.enable_checkpointing(Revolve(steps, 5))`. In this case, we are informing the code to use Revolve algorithmic, where the forward data stored in memory is only for 5 steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af46e31-5af1-4634-97f4-0eecedd11051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_burgers_newton():\n",
    "    \"\"\"\n",
    "    Adjoint-based gradient tests with and without checkpointing.\n",
    "    \"\"\"\n",
    "    tape = get_working_tape()\n",
    "    tape.progress_bar = ProgressBar\n",
    "    tape.enable_checkpointing(Revolve(steps, 5))\n",
    "    x, = SpatialCoordinate(mesh)\n",
    "    ic = project(sin(2.*pi*x), V)\n",
    "    val = J(ic, solve_type, True)\n",
    "    if checkpointing:\n",
    "        assert len(tape.timesteps) == steps\n",
    "\n",
    "    Jhat = ReducedFunctional(val, Control(ic))\n",
    "    dJ = Jhat.derivative()\n",
    "    # Test recompute forward model\n",
    "    assert(np.allclose(Jhat(ic), val))\n",
    "\n",
    "    dJbar = Jhat.derivative()\n",
    "    # Test recompute adjoint-based gradient\n",
    "    assert np.allclose(dJ.dat.data_ro[:], dJbar.dat.data_ro[:])\n",
    "\n",
    "    # Taylor test\n",
    "    h = Function(V)\n",
    "    h.assign(1, annotate=False)\n",
    "    assert taylor_test(Jhat, ic, h) > 1.9\n",
    "    print(\"Taylor tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f088f-9e44-4626-a356-23408c88d470",
   "metadata": {},
   "source": [
    "Additionally, we compare the adjoint-based gradient results with and without checkpointing witht the function `test_checkpointing_validity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d3a580f-a96a-4aa6-a7d8-1038ce8e64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_checkpointing_validity():\n",
    "    \"\"\"Compare forward and backward results with and without checkpointing.\n",
    "    \"\"\"\n",
    "    # Without checkpointing\n",
    "    tape = get_working_tape()\n",
    "    x, = SpatialCoordinate(mesh)\n",
    "    ic = project(sin(2.*pi*x), V)\n",
    "\n",
    "    val0 = J(ic, solve_type, False)\n",
    "    Jhat = ReducedFunctional(val0, Control(ic))\n",
    "    dJ0 = Jhat.derivative()\n",
    "    val00 = Jhat(project(sin(1.*pi*x), V))\n",
    "    dJ00 = Jhat.derivative()\n",
    "    tape.clear_tape()\n",
    "    print(\"Without checkpointing\")\n",
    "    # With checkpointing\n",
    "    tape.progress_bar = ProgressBar\n",
    "    tape.enable_checkpointing(Revolve(steps, 1))\n",
    "    x, = SpatialCoordinate(mesh)\n",
    "    ic = project(sin(2.*pi*x), V)\n",
    "    val1 = J(ic, solve_type, True)\n",
    "    tape.visualise(\"tape_before_recompute.pdf\")\n",
    "    Jhat = ReducedFunctional(val1, Control(ic))\n",
    "    dJ1 = Jhat.derivative()\n",
    "    val11 = Jhat(project(sin(1.*pi*x), V))\n",
    "\n",
    "    tape.visualise(\"tape_after_recompute.pdf\")\n",
    "    dJ11 = Jhat.derivative()\n",
    "    tape.visualise(\"tape_after_gradient.pdf\")\n",
    "    assert len(tape.timesteps) == steps\n",
    "    assert np.allclose(val0, val1)\n",
    "    assert np.allclose(dJ0.dat.data_ro[:], dJ1.dat.data_ro[:])\n",
    "    print(\"Comparisons between automated gradient with and without checkpoint are working as expected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb41d69-cc86-4bb6-8292-73b27531e801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taping forward ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without checkpointing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Adjoint ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 21/21 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Adjoint ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 21/21 [0:00:00]\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparisons between automated gradient with and without checkpoint are working as expected!\n"
     ]
    }
   ],
   "source": [
    "test_checkpointing_validity()\n",
    "tape = get_working_tape()\n",
    "tape.clear_tape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e76ef45-a22c-4c19-93e1-dbb0efb84d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Taping forward ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Adjoint ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 11/11 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Adjoint ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 11/11 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Adjoint ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 11/11 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]\n",
      "Evaluating Functional ▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣▣ 6/6 [0:00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Taylor test\n",
      "Computed residuals: [0.0001981937668922317, 4.9548558052393515e-05, 1.2387146782200635e-05, 3.0967871499368214e-06]\n",
      "Computed convergence rates: [1.9999966128589979, 1.9999991533885053, 1.9999997883156315]\n",
      "Taylor tests passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "test_burgers_newton()\n",
    "tape.clear_tape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7073b-b71e-428d-bdcf-386aa2560914",
   "metadata": {},
   "source": [
    "The tests above are working as expected! Now, let us consider another time dependent optimisation problem with checkpointing approach. The next notebook is simplified implementation of a Full Inversion problem.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
